# CORTEX Architecture Blueprint
## Stateless Context-Passing fÃ¼r AI-zu-AI Dialog

---

## ðŸ—ï¸ **CORE ARCHITECTURE PRINCIPLES**

### **1. Stateless Context-Passing**
- **Kein Session Management** - Jeder AI-Call ist unabhÃ¤ngig
- **Context via Prompt** - Vorherige Antworten werden in den Prompt eingebettet
- **API-Agnostic** - Funktioniert mit jeder AI-API (Claude, ChatGPT, Gemini, Qwen)

### **2. Intelligent Context Limits**
- **Smart Truncation** - Erste 800-1200 Zeichen pro AI-Antwort als Context
- **Front-Loading Rules** - AIs lernen: Kernaussagen an den Anfang
- **Token-Explosion Prevention** - Feste Limits verhindern exponentielles Wachstum

### **3. Echte Iterative Dialoge**
- **Sequential Rounds** - Alle AIs parallel pro Runde
- **Cross-Referencing** - AIs beziehen sich explizit aufeinander
- **Dialog Evolution** - Aufbau Ã¼ber mehrere Runden hinweg

---

## ðŸ”„ **SYSTEM FLOW ARCHITECTURE**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CORTEX SESSION FLOW                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. INPUT PHASE
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  User Question  â”‚ â†’ Original Prompt (200 Tokens)
   â”‚  + AI Team      â”‚   
   â”‚  + Parameters   â”‚   
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. ITERATION ROUND (Parallel Processing)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   AI 1: Claude  â”‚    â”‚  AI 2: ChatGPT  â”‚    â”‚   AI 3: Gemini  â”‚
   â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
   â”‚ Prompt Building â”‚    â”‚ Prompt Building â”‚    â”‚ Prompt Building â”‚
   â”‚ â”œâ”€Original Q.   â”‚    â”‚ â”œâ”€Original Q.   â”‚    â”‚ â”œâ”€Original Q.   â”‚
   â”‚ â”œâ”€Context (1.2k)â”‚    â”‚ â”œâ”€Context (1.2k)â”‚    â”‚ â”œâ”€Context (1.2k)â”‚
   â”‚ â””â”€Front Rules   â”‚    â”‚ â””â”€Front Rules   â”‚    â”‚ â””â”€Front Rules   â”‚
   â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
   â”‚ Response (2k)   â”‚    â”‚ Response (2k)   â”‚    â”‚ Response (2k)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                       â”‚                       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚               CONTEXT PREPARATION                           â”‚
   â”‚                                                             â”‚
   â”‚  Smart Truncation: First 1200 chars per response           â”‚
   â”‚  â”œâ”€ Sentence-aware cutting (no mid-sentence breaks)        â”‚
   â”‚  â”œâ”€ Preserve key insights through front-loading            â”‚
   â”‚  â””â”€ Total context: ~6k chars for next round                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. NEXT ITERATION (Repeat 2-5 times)
   Same parallel processing, but with enriched context

4. OUTPUT SYNTHESIS
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                    FINAL REPORT                             â”‚
   â”‚                                                             â”‚
   â”‚  â€¢ Executive Summary                                        â”‚
   â”‚  â€¢ Key Insights Matrix                                      â”‚
   â”‚  â€¢ Convergence/Divergence Analysis                          â”‚
   â”‚  â€¢ Actionable Recommendations                               â”‚
   â”‚  â€¢ Raw Dialog Transcript                                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ§  **PROMPT CONSTRUCTION ARCHITECTURE**

### **Dynamic Prompt Builder**
```python
def build_cortex_prompt(
    original_question: str,
    ai_role: str,
    iteration_number: int,
    previous_context: List[str],  # Already truncated responses
    front_loading_rules: Dict
) -> str:

    # Template Structure:
    """
    ROLE: {ai_role} - {unique_perspective}
    
    ITERATION {iteration_number}: {original_question}
    
    COMMUNICATION RULES:
    - Kernaussagen in erste 200 Zeichen
    - Explizite Referenzen auf andere AIs
    - Aufbau auf vorherigen Insights
    
    PREVIOUS CONTRIBUTIONS:
    [Claude]: {truncated_response_1200_chars}...
    [ChatGPT]: {truncated_response_1200_chars}...
    [Gemini]: {truncated_response_1200_chars}...
    
    YOUR TASK:
    - Iteration 1: ErÃ¶ffne mit deiner Position
    - Iteration 2-4: Baue auf anderen auf, bringe neue Perspektiven
    - Iteration 5: Synthese und Schlussfolgerungen
    """
```

### **Context Limit Calculator**
```python
CONTEXT_LIMITS = {
    "team_size_3": 1200,    # Mehr Detail pro AI mÃ¶glich
    "team_size_5": 1000,    # Standard Setup
    "team_size_7": 800,     # Kompaktere Contexts nÃ¶tig
    "team_size_10": 600     # Maximum Compression
}

def calculate_context_budget(num_ais: int, max_iterations: int) -> int:
    """
    Dynamische Context-Limits basierend auf Team-GrÃ¶ÃŸe
    Ziel: Max 50k Tokens total per Session
    """
    base_limit = 50000 // (num_ais * max_iterations)
    return min(1200, max(600, base_limit))
```

---

## ðŸ“Š **TOKEN MANAGEMENT ARCHITECTURE**

### **Token Budget System**
```
SESSION BUDGET EXAMPLE (5 AIs, 3 Iterations):

Iteration 1:
â”œâ”€ Input: 5 Ã— 200 tokens (original prompt) = 1,000 tokens
â”œâ”€ Output: 5 Ã— 1,500 tokens (responses) = 7,500 tokens
â””â”€ Context Prep: 5 Ã— 1,000 chars â†’ 5,000 tokens

Iteration 2:
â”œâ”€ Input: 5 Ã— (200 + 1,000) tokens = 6,000 tokens
â”œâ”€ Output: 5 Ã— 1,500 tokens = 7,500 tokens
â””â”€ Context Prep: 5 Ã— 1,000 chars â†’ 5,000 tokens

Iteration 3:
â”œâ”€ Input: 5 Ã— (200 + 2,000) tokens = 11,000 tokens
â”œâ”€ Output: 5 Ã— 1,500 tokens = 7,500 tokens

TOTAL SESSION: ~45,000 tokens (~$0.90 at GPT-4 pricing)
```

### **Smart Truncation Algorithm**
```python
def smart_truncate(response: str, limit: int = 1000) -> str:
    """
    Sentence-aware truncation preserving meaning
    """
    if len(response) <= limit:
        return response
    
    # Find last complete sentence within limit
    sentences = response.split('. ')
    result = ""
    
    for sentence in sentences:
        potential = result + sentence + ". "
        if len(potential) <= limit:
            result = potential
        else:
            break
    
    return result + "..." if result != response else result
```

---

## ðŸŽ¯ **FRONT-LOADING RULES SYSTEM**

### **AI Communication Optimization**
```python
FRONT_LOADING_RULES = {
    "key_points_first": {
        "instruction": "Erste 200 Zeichen: Deine Hauptthese",
        "example": "Hauptpunkt: X ist falsch weil Y. [Details folgen...]"
    },
    
    "explicit_references": {
        "instruction": "Beziehe dich direkt auf andere AIs",
        "example": "Claude erwÃ¤hnte X, aber ich sehe Problem Y..."
    },
    
    "dense_communication": {
        "instruction": "Maximiere Informationsdichte",
        "example": "Statt 'Das ist interessant' â†’ 'Das lÃ¶st Problem X'"
    },
    
    "meta_coordination": {
        "instruction": "Erkenne Diskussionsmuster",
        "example": "Wir konvergieren bei X, divergieren bei Y"
    }
}
```

---

## ðŸ”§ **IMPLEMENTATION COMPONENTS**

### **Core Modules**
```
cortex/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ session_manager.py      # Session lifecycle
â”‚   â”œâ”€â”€ prompt_builder.py       # Dynamic prompt construction
â”‚   â”œâ”€â”€ context_processor.py    # Smart truncation & limits
â”‚   â””â”€â”€ ai_orchestrator.py      # Parallel API coordination
â”‚
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ anthropic_api.py        # Claude integration
â”‚   â”œâ”€â”€ openai_api.py           # ChatGPT integration
â”‚   â”œâ”€â”€ google_api.py           # Gemini integration
â”‚   â””â”€â”€ openrouter_api.py       # Multi-provider access
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ token_calculator.py     # Budget management
â”‚   â”œâ”€â”€ truncation.py           # Smart context limits
â”‚   â””â”€â”€ report_generator.py     # Output synthesis
â”‚
â””â”€â”€ config/
    â”œâ”€â”€ ai_profiles.py          # AI roles & personalities
    â”œâ”€â”€ ruleset_library.py      # Front-loading rules
    â””â”€â”€ limits.py               # Context & token limits
```

### **Data Flow Interfaces**
```python
# Session Input
class CortexSession:
    question: str
    ai_team: List[str]          # ["claude", "chatgpt", "gemini"]
    max_iterations: int = 3
    context_limit: int = 1000
    front_loading_rules: Dict

# Iteration State
class IterationRound:
    round_number: int
    responses: Dict[str, str]   # ai_name â†’ response
    truncated_context: Dict[str, str]  # ai_name â†’ first 1000 chars
    token_usage: Dict[str, int]

# Final Output
class CortexReport:
    executive_summary: str
    key_insights: List[str]
    convergence_analysis: str
    divergence_points: List[str]
    raw_transcript: List[IterationRound]
    token_usage_total: int
```

---

## ðŸš€ **SCALABILITY & PERFORMANCE**

### **Horizontal Scaling**
- **AI Team Size:** 3-10 AIs per session
- **Concurrent Sessions:** Multiple independent sessions
- **API Load Balancing:** Distribute across providers

### **Performance Optimization**
- **Parallel Processing:** All AIs in round process simultaneously
- **Context Caching:** Reuse truncated contexts within session
- **Token Prediction:** Estimate costs before execution

### **Quality Assurance**
- **Context Quality Metrics:** Measure information preservation
- **Cross-Reference Tracking:** Monitor AI-to-AI dialogue depth
- **Emergence Detection:** Identify novel insights from collaboration

---

## ðŸ’¡ **IMPLEMENTATION PRIORITIES**

### **Phase 1: MVP (Week 1)**
1. âœ… **Basic Prompt Builder** - Dynamic context injection
2. âœ… **Smart Truncation** - Sentence-aware limits
3. âœ… **Parallel AI Calls** - Async processing
4. âœ… **Simple Report Generation** - Raw output formatting

### **Phase 2: Enhancement (Week 2)**
1. ðŸ”„ **Front-Loading Rules** - Communication optimization
2. ðŸ”„ **Token Budget Management** - Cost control
3. ðŸ”„ **Quality Metrics** - Dialogue depth measurement
4. ðŸ”„ **Web Interface** - User-friendly session management

### **Phase 3: Production (Week 3-4)**
1. ðŸ“‹ **Advanced Reporting** - Insight synthesis
2. ðŸ“‹ **Performance Optimization** - Speed & reliability
3. ðŸ“‹ **Scale Testing** - Large teams & long sessions
4. ðŸ“‹ **Integration Testing** - Real-world use cases

---

**Status:** Architecture Blueprint Complete - Ready for Implementation  
**Next:** Begin Phase 1 MVP Development with Focus on Core Components